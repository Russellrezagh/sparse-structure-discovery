{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "path_to_ci = \"BBQ_results_test/CI_after_localization_round_2_cc_0.1_lt2_0.0_width_50_std_2.pickle\"\n",
    "loci, loci_lists = pickle.load(open(path_to_ci,\"rb\"))\n",
    "print(len(loci), len(loci_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = path_to_ci.split(\".\")[0]+\"_orf_and_anno\"\n",
    "print(new_dir)\n",
    "try:\n",
    "    os.mkdir(new_dir)\n",
    "except:\n",
    "    print(f\"already have directory {new_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,li in enumerate(loci_lists):\n",
    "    z = \" \".join([str(_) for _ in li])\n",
    "    ! python /n/desai_lab/users/efenton/bbq/yeast_info/get_orf.py {z} > {new_dir}/orf_out_{i}.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loci = [i for j in loci_lists for i in j]\n",
    "loci_to_orf_d = dict.fromkeys(all_loci)\n",
    "for i,li in enumerate(loci_lists):\n",
    "    orf_file = f\"{new_dir}/orf_out_{i}.txt\"\n",
    "    print(orf_file)\n",
    "    fh = open(orf_file, 'r')\n",
    "    success_loci= []\n",
    "    orfs = []\n",
    "    loci_time = False\n",
    "    orf_time = False\n",
    "    for line in fh.readlines():\n",
    "        if loci_time:\n",
    "            new_loci = line.split()\n",
    "            if new_loci[0]=='[]':\n",
    "                print(\"none annotated\")\n",
    "                break\n",
    "            #print(new_loci)\n",
    "            if new_loci[0][0]=='[':\n",
    "                if new_loci[0]=='[':\n",
    "                    new_loci = new_loci[1:]\n",
    "                else:\n",
    "                    new_loci[0] = new_loci[0][1:]\n",
    "            if new_loci[-1][-1]==']':\n",
    "                new_loci[-1] = new_loci[-1][:-1]\n",
    "                loci_time = False\n",
    "            #print(new_loci)\n",
    "            success_loci += [int(_) for _ in new_loci]\n",
    "        if orf_time:\n",
    "            orfs = [x[7:-1] for x in line.split(',')[:-1]] + [line.split(',')[-1][7:-3]]\n",
    "        if line.startswith(\"Named\"):\n",
    "            loci_time = True\n",
    "        if line.startswith(\"Gene\"):\n",
    "            orf_time = True\n",
    "    if len(orfs)!= len(success_loci):\n",
    "        raise ValueError(\"different number of ORFs and loci...something went wrong\")\n",
    "    fh.close()\n",
    "    #print(orfs, success_loci)\n",
    "    for _, loci in enumerate(success_loci):\n",
    "       # print(loci, orfs[_])\n",
    "        loci_to_orf_d[loci] = orfs[_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loci_to_possible_orfs_d = {}\n",
    "all_possible_orfs = []\n",
    "all_orfs = []\n",
    "for ind in range(num_to_localize):\n",
    "    l = idx_filt[ind]\n",
    "    ls = loci_filt[ind]\n",
    "    plt.figure(figsize = (20,10))\n",
    "    plt.imshow(to_plot[ind], vmin = -.03, vmax = .03, cmap =\"bwr_r\")\n",
    "    plt.title(ls, fontsize = 20)\n",
    "    plt.show()\n",
    "    for _ in sorted(loci_lists[ind]):\n",
    "        print(loci_to_orf_d[_], _)\n",
    "    possible_orfs = set([loci_to_orf_d[_] for _ in loci_lists[ind]])\n",
    "    possible_orfs = [ _ for _ in possible_orfs if _ is not None]\n",
    "    all_possible_orfs.append(possible_orfs)\n",
    "    all_orfs+=possible_orfs\n",
    "    print(\"\\n\")\n",
    "    print(possible_orfs)\n",
    "    loci_to_possible_orfs_d[ls]= possible_orfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(num_to_localize), [len(_) for _ in all_possible_orfs], alpha= .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist([len(_) for _ in all_possible_orfs[:30]], bins = np.arange(0,10,1))\n",
    "plt.title(\"top 30 loci\")\n",
    "plt.xlabel(\"number of ORFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save annotations and adjcent info\n",
    "\n",
    "fh = open(f\"{new_dir}/orf_names.txt\", \"w\")\n",
    "fh.write(\" \".join(all_orfs))\n",
    "fh.close()\n",
    "\n",
    "pickle.dump(loci_to_possible_orfs_d, open(f\"{new_dir}/loci_to_possible_orfs_d\", \"wb\"))\n",
    "#loci_to_possible_orfs_d = pickle.load(open(f\"{new_dir}/loci_to_possible_orfs_d\", \"rb\"))\n",
    "\n",
    "# upload file for process and function annotations here: https://www.yeastgenome.org/goSlimMapper\n",
    "# had to remove ambigous results-> gofriendly\n",
    "# save tab delinated results to \n",
    "fun_anno = f\"{new_dir}/go_annotations_function.txt\"\n",
    "proc_anno = f\"{new_dir}/go_annotations_process.txt\"\n",
    "\n",
    "# use https://yeastmine.yeastgenome.org/yeastmine/begin.do to get annotations for orf_names.txt \n",
    "# ignored ones with ambigous labels\n",
    "# save tab delinated results to \n",
    "gene_anno = f\"{new_dir}/gene_anno.tsv\"\n",
    "\n",
    "all_orfs = []\n",
    "for key in loci_to_possible_orfs_d:\n",
    "    all_orfs += loci_to_possible_orfs_d[key]\n",
    "print(len(all_orfs))\n",
    "all_orfs = list(set(all_orfs))\n",
    "print(len(all_orfs))\n",
    "\n",
    "df = pd.read_csv(gene_anno, sep = '\\t', header=None)#, cols = [\"name1\", \"name2\", \"func\",\"description\"])\n",
    "df = df.set_index(0)\n",
    "df.rename(columns = {0:'Systematic Gene Name', 1:'Standard Gene Name',2:'Long Gene Name',3:'Brief Description',4:'Description', 5:'Function Summary'}, inplace = True)\n",
    "\n",
    "\n",
    "for orf in all_orfs:\n",
    "    if orf not in df.index:\n",
    "        df.loc[orf] = [None, None, None, None, None]\n",
    "\n",
    "df\n",
    "\n",
    "cl_description_proc\n",
    "\n",
    "cl_description_proc = dict.fromkeys(df.index)\n",
    "for key in cl_description_proc:\n",
    "    cl_description_proc[key] = []\n",
    "fh = open(proc_anno, 'r')\n",
    "fh.readline()\n",
    "for line in fh.readlines():\n",
    "    ll = line.split('\\t')\n",
    "    name = f\"{ll[1]} ({ll[2]})\"\n",
    "    li = ll[-1].strip().split(', ')\n",
    "    for _ in li:\n",
    "        if _==\"SNR30\": _ = \"snR30\"\n",
    "        if _==\"TP(UGG)O3\": _ = \"tP(UGG)O3\"\n",
    "        cl_description_proc[_].append(name)\n",
    "for _ in cl_description_proc.keys():\n",
    "    cl_description_proc[_] = \" \".join(cl_description_proc[_])\n",
    "\n",
    "\n",
    "cl_description_func = dict.fromkeys(df.index)\n",
    "for key in cl_description_func:\n",
    "    cl_description_func[key] = []\n",
    "fh = open(fun_anno, 'r')\n",
    "fh.readline()\n",
    "for line in fh.readlines():\n",
    "    ll = line.split('\\t')\n",
    "    name = f\"{ll[1]} ({ll[2]})\"\n",
    "    li = ll[-1].strip().split(', ')\n",
    "    for _ in li:\n",
    "        if _==\"SNR30\": _ = \"snR30\"\n",
    "        if _==\"TP(UGG)O3\": _ = \"tP(UGG)O3\"\n",
    "        cl_description_func[_].append(name)\n",
    "for _ in cl_description_func.keys():\n",
    "    cl_description_func[_] = \" \".join(cl_description_func[_])\n",
    "\n",
    "\n",
    "df[\"GO_Function\"] = [cl_description_func[_] for _ in df.index]\n",
    "df[\"GO_Process\"] = [cl_description_proc[_] for _ in df.index]\n",
    "\n",
    "df\n",
    "\n",
    "df.to_csv(f'{new_dir}/orf_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
