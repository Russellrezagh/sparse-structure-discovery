{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to process the BBQ data and performs the following tasks:\n",
    "1. Reads in separate phenotype measurements files and puts them in one array\n",
    "2. Splits genotype and phenotypes arrays into train/test/validation and saves them\n",
    "3. Computes correlation coeff for each loci and and its neighbors (based only on the genotype training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already have directory ./BBQ_data_processed\n"
     ]
    }
   ],
   "source": [
    "#environments (phenotypes)\n",
    "envs=[\"ynb\",\"suloc\",\"raff\",\"mol\",\"27C\",\"eth\",\"30C\",\"25C\",\"sds\",\"cu\",\"33C\",\"li\",\"gu\",\"23C\",\"35C\",\"mann\",\"37C\", \"4NQO\"]\n",
    "envs= sorted(envs)\n",
    "\n",
    "# find phenotype input files; should be in form <path_to_files>_<env>_<suffix>\n",
    "pheno_path = \"./BBQ_data/pheno_data_\"\n",
    "file_suffix = \".txt\"\n",
    "input_geno_file = \"./BBQ_data/geno_data_bool_99950.npy\"\n",
    "\n",
    "# specify output directory. create directory if it does not exist. \n",
    "output_dir = \"./BBQ_data_processed\"\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except:\n",
    "    print(f\"already have directory {output_dir}\")\n",
    "\n",
    "#truncate data to first N strains\n",
    "truncate = False\n",
    "N = 99950\n",
    "\n",
    "#train/validation/test fractions\n",
    "train_frac = 0.80\n",
    "validation_frac = 0.10\n",
    "test_frac = 0.10\n",
    "seed = 0\n",
    "if train_frac+validation_frac+test_frac != 1.0:\n",
    "    raise ValueError(\"fractions for train/validation/test must sum to one\")\n",
    "\n",
    "# compute correlation coeff for each position and max_loci_cc positions in front\n",
    "max_loci_cc = 200 # compute correlation coeff for each position and max_loci_cc positions in front"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load genotype and phenotype files,  make one array from phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pheno_from_file(filename,N): \n",
    "    Y = np.genfromtxt(filename,skip_header = 1, skip_footer = 1, usecols = (1))\n",
    "    Y = Y[:N]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phenotype shape\n",
      "(99950, 18)\n"
     ]
    }
   ],
   "source": [
    "P = np.zeros((N,len(envs)))\n",
    "for i, phen in enumerate(envs):\n",
    "    filename = f\"{pheno_path}{phen}.txt\"\n",
    "    P[:,i]= get_pheno_from_file(filename,N)\n",
    "print(\"phenotype shape\")\n",
    "print(P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genotype shape\n",
      "(99950, 41594)\n"
     ]
    }
   ],
   "source": [
    "G = np.load(input_geno_file)\n",
    "print(\"genotype shape\")\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load genotype file, divide geno + pheno into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering out 8206 segregants due to a nan value for some phenotype\n",
      "phenotype shape\n",
      "(91744, 18)\n",
      "genotype shape\n",
      "(91744, 41594)\n"
     ]
    }
   ],
   "source": [
    "# filter out segregants with NaN fitness\n",
    "filter_out_nan = P==P\n",
    "filter_out_nan = np.sum(filter_out_nan, axis = -1 ) == len(envs)\n",
    "print(f\"filtering out {P.shape[0]-sum(filter_out_nan)} segregants due to a nan value for some phenotype\") \n",
    "G = G[filter_out_nan,:]\n",
    "P = P[filter_out_nan,:]\n",
    "print(\"phenotype shape\")\n",
    "print(P.shape)\n",
    "print(\"genotype shape\")\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sizes: (73395, 41594), (73395, 18)\n",
      "validation sizes: (9175, 41594), (9175, 18)\n",
      "test sizes: (9174, 41594), (9174, 18)\n"
     ]
    }
   ],
   "source": [
    "# split data into train/validation/test\n",
    "np.random.seed(seed)\n",
    "X = G\n",
    "Y = P\n",
    "\n",
    "filt = np.random.choice(len(X), size = int(train_frac*len(X)), replace = False)\n",
    "split = np.zeros(len(X),dtype=bool)\n",
    "split[filt] = 1\n",
    "Xtrain = X[split]\n",
    "Ytrain = Y[split]\n",
    "Xval = X[~split]\n",
    "Yval = Y[~split]\n",
    "\n",
    "vfilt = np.random.choice(len(Xval), size = int(validation_frac/(validation_frac + test_frac) *len(Xval)), replace = False)\n",
    "vsplit = np.zeros(len(Xval),dtype=bool)\n",
    "vsplit[vfilt] = 1\n",
    "Xtest = Xval[vsplit]\n",
    "Ytest = Yval[vsplit]\n",
    "Xval = Xval[~vsplit]\n",
    "Yval = Yval[~vsplit]\n",
    "\n",
    "print(f\"training sizes: {Xtrain.shape}, {Ytrain.shape}\")\n",
    "print(f\"validation sizes: {Xval.shape}, {Yval.shape}\")\n",
    "print(f\"test sizes: {Xtest.shape}, {Ytest.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "np.save(open(f\"{output_dir}/geno_train.npy\", \"wb\"),Xtrain)\n",
    "np.save(open(f\"{output_dir}/pheno_train.npy\", \"wb\"),Ytrain)\n",
    "np.save(open(f\"{output_dir}/geno_val.npy\", \"wb\"),Xval)\n",
    "np.save(open(f\"{output_dir}/pheno_val.npy\", \"wb\"),Yval)\n",
    "np.save(open(f\"{output_dir}/geno_test.npy\", \"wb\"),Xtest)\n",
    "np.save(open(f\"{output_dir}/pheno_test.npy\", \"wb\"),Ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute pairwise correlations for each loci and max_loci_cc neighbors (slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5000\n",
      "5000 10000\n",
      "10000 15000\n",
      "15000 20000\n",
      "20000 25000\n",
      "25000 30000\n",
      "30000 35000\n",
      "35000 40000\n",
      "40000 45000\n"
     ]
    }
   ],
   "source": [
    "g = 2*g-1\n",
    "stdg = []\n",
    "l=5000\n",
    "for _ in range(int(g.shape[1]/l)+1):\n",
    "    print(_*l,(_+1)*l)\n",
    "    stdg += list(np.std(g[:,_*l:(_+1)*l], axis = 0))\n",
    "stdg= np.array(stdg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = np.mean(g, axis = 0)\n",
    "ng = g-mg\n",
    "ostdg=1/stdg\n",
    "for _ in range(int(g.shape[1]/l)+1):\n",
    "    ng[:,_*l:(_+1)*l] = ng[:,_*l:(_+1)*l]*ostdg[_*l:(_+1)*l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "correlation shape\n",
      "(41594, 200)\n"
     ]
    }
   ],
   "source": [
    "ml = max_loci_cc\n",
    "cc = np.zeros((g.shape[1], ml))\n",
    "for _ in range(g.shape[1]):\n",
    "    if _%1000==0: print(_)\n",
    "    ccs=np.einsum('j,jk->k', ng[:,_], ng[:, _+1:_+ml+1])/ng.shape[0]\n",
    "    cc[_,0:int(ccs.shape[0])]=ccs\n",
    "print(\"correlation shape\")\n",
    "print(cc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved array at ./BBQ_data_processed/cc_data_all.npy\n"
     ]
    }
   ],
   "source": [
    "np.save(open(f\"{output_dir}/cc_data_all.npy\", \"wb\"), cc)\n",
    "print(f\"saved array at {output_dir}/cc_data_all.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
